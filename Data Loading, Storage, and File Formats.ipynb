{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading, Storage, and File Formats\n",
    "---\n",
    "DAT 512 Canisuis College <br>\n",
    "Professor Paul Lambson<br>\n",
    "<br>\n",
    "### Learning Objectives\n",
    "- Become familiar with ways to load data into pandas\n",
    "- Become confident with loading simple data\n",
    "- Learn about multiple datatypes\n",
    "- Learn how to write data from pandas to files\n",
    "- Learn a simple method for access data from APIs\n",
    "- Learn how to create a lightweigh database\n",
    "<br>\n",
    "\n",
    "\n",
    "### Sections\n",
    "- [Reading and Writing Data in Text Format](#reading-and-writing-data-in-text-format)\n",
    "- [Reading Text Files in Pieces](#reading-text-files-in-pieces)\n",
    "- [Writing Data to Text Format](#writing-data-to-text-format)\n",
    "- [Working With Other Delimited Formats](#working-with-other-delimited-formats)\n",
    "- [JSON Data](#json-data)\n",
    "- [HTML Web Scraping](#html-web-scraping)\n",
    "- [Binary Data Formats](#binary-data-formats)\n",
    "- [Reading Microsoft Excel Formats](#reading-microsoft-excel-files)\n",
    "- [Interacting with Databases](#interacting-with-databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "pd.options.display.max_colwidth = 75\n",
    "pd.options.display.max_columns = 20\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reading-and-writing-data-in-text-format'></a>\n",
    "# Reading and Writing Data in Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a text file\n",
    "!cat examples/ex1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in text file, look at pd.read_ options\n",
    "df = pd.read_csv(\"examples/ex1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=04eaafad5e034dd888ca309bfa6fd75c\n",
    "!cat examples/ex2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file has no headers\n",
    "pd.read_csv(\"examples/ex2.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names keyword can pass a list of column names\n",
    "pd.read_csv(\"examples/ex2.csv\", names=[\"a\", \"b\", \"c\", \"d\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use a named list to put into names and identify the index\n",
    "names = [\"a\", \"b\", \"c\", \"d\", \"message\"]\n",
    "pd.read_csv(\"examples/ex2.csv\", names=names, index_col=\"message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutliindex is a possiblilty\n",
    "!cat examples/csv_mindex.csv\n",
    "parsed = pd.read_csv(\"examples/csv_mindex.csv\",\n",
    "                     index_col=[\"key1\", \"key2\"])\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider an irregularly delimitted file\n",
    "!cat examples/ex3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use regex to parse\n",
    "result = pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can skip rows if needed\n",
    "!cat examples/ex4.csv\n",
    "pd.read_csv(\"examples/ex4.csv\", skiprows=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values shown as NaN\n",
    "!cat examples/ex5.csv\n",
    "result = pd.read_csv(\"examples/ex5.csv\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use isna to find missing data\n",
    "pd.isna(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can add to the list of items that are recognized as NaN\n",
    "result = pd.read_csv(\"examples/ex5.csv\", na_values=[\"NULL\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not keeping default na will break .isna()\n",
    "result2 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False,\n",
    "                      na_values=[\"NA\"])\n",
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different NA sentinels can be specified for each column in a dictionary\n",
    "sentinels = {\"message\": [\"foo\", \"NA\"], \"something\": [\"two\"]}\n",
    "pd.read_csv(\"examples/ex5.csv\", na_values=sentinels,\n",
    "\n",
    "            keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reading-text-files-in-pieces'></a>\n",
    "# Reading Text Files in Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease display for larger files\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the elipsis '...' that indicated data that is not shown\n",
    "result = pd.read_csv(\"examples/ex6.csv\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could read in only a smalle amount of rows\n",
    "pd.read_csv(\"examples/ex6.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read in a file in peices a chunksize can be specified\n",
    "chunker = pd.read_csv(\"examples/ex6.csv\", chunksize=1000)\n",
    "type(chunker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over a file to add key.value_counts() to a series\n",
    "chunker = pd.read_csv(\"examples/ex6.csv\", chunksize=1000)\n",
    "\n",
    "tot = pd.Series([], dtype='int64')\n",
    "for piece in chunker:\n",
    "    tot = tot.add(piece[\"key\"].value_counts(), fill_value=0)\n",
    "\n",
    "tot = tot.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of chunking\n",
    "tot[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='writing-data-to-text-format'></a>\n",
    "# Writing Data to Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead a dataframe to write\n",
    "data = pd.read_csv(\"examples/ex5.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to_csv(), look at other to options\n",
    "data.to_csv(\"examples/out.csv\")\n",
    "!cat examples/out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other delimiters can be used, of course \n",
    "# (writing to sys.stdout so it prints the text result to the console rather than a file)\n",
    "import sys\n",
    "data.to_csv(sys.stdout, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write nulls as a custom representation\n",
    "data.to_csv(sys.stdout, na_rep=\"NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping index and headers\n",
    "data.to_csv(sys.stdout, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping index, overwriting column names\n",
    "data.to_csv(sys.stdout, index=False, columns=[\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='working-with-other-delimited-formats'></a>\n",
    "# Working with Other Delimited Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a file is more complicated than read_csv() can handle, move into csv library\n",
    "!cat examples/ex7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using csv library\n",
    "import csv\n",
    "f = open(\"examples/ex7.csv\")\n",
    "reader = csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv readers iterate over a file, this is the core ETL process\n",
    "for line in reader:\n",
    "    print(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if doing the wrangling then move through this list of steps\n",
    "# list of lines\n",
    "with open(\"examples/ex7.csv\") as f:\n",
    "    lines = list(csv.reader(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first line is headers, following lines are values\n",
    "header, values = lines[0], lines[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that has headers and zipped values, then load to data frame\n",
    "data_dict = {h: v for h, v in zip(header, zip(*values))}\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='json-data'></a>\n",
    "# JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin with an string that is a json\n",
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use python json library to convert to actual json\n",
    "import json\n",
    "result = json.loads(obj)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be turned back into a string\n",
    "asjson = json.dumps(result)\n",
    "asjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transverse a JSON in order to load a child dictionary\n",
    "siblings = pd.DataFrame(result[\"siblings\"], columns=[\"name\", \"age\"])\n",
    "siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "!cat examples/example.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas has a read_json() option for relatively uniform JSON objects\n",
    "data = pd.read_json(\"examples/example.json\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options exist to write a file\n",
    "data.to_json(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns or row first\n",
    "data.to_json(sys.stdout, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='html-web-scraping'></a>\n",
    "# HTML Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a html file that holds a table\n",
    "tables = pd.read_html(\"examples/fdic_failed_bank_list.html\")\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = tables[0]\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a date field to timestamp\n",
    "close_timestamps = pd.to_datetime(failures[\"Closing Date\"])\n",
    "close_timestamps.dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='binary-data-formats'></a>\n",
    "# Binary Data Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One simple way to store (or serialize) data in binary format is using Pythonâ€™s built-in pickle module\n",
    "frame = pd.read_csv(\"examples/ex1.csv\")\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_pickle(\"examples/frame_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read back pickle\n",
    "pd.read_pickle(\"examples/frame_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the example file\n",
    "!rm examples/frame_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support of Apache Parquet\n",
    "fec = pd.read_parquet('examples/fec.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reading-microsoft-excel-files'></a>\n",
    "# Reading Microsoft Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a excel file\n",
    "xlsx = pd.ExcelFile(\"examples/ex1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at sheet names\n",
    "xlsx.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed a sheet into a data frame\n",
    "xlsx.parse(sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate an index col\n",
    "xlsx.parse(sheet_name=\"Sheet1\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are just reading in one sheet, pass that value\n",
    "frame = pd.read_excel(\"examples/ex1.xlsx\", sheet_name=\"Sheet1\")\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing excel require initialization of a writer\n",
    "writer = pd.ExcelWriter(\"examples/ex2.xlsx\")\n",
    "frame.to_excel(writer, \"Sheet1\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also to_excel() which will \n",
    "frame.to_excel(\"examples/ex2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete files\n",
    "!rm examples/ex2.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the last 30 GitHub issues for pandas on GitHub\n",
    "# we can make a GET HTTP request using the add-on requests library\n",
    "import requests\n",
    "url = \"https://api.github.com/repos/pandas-dev/pandas/issues\"\n",
    "resp = requests.get(url)\n",
    "resp.raise_for_status()\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the response into json and view first \n",
    "data = resp.json()\n",
    "data[0][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the elements to load into the data frame\n",
    "issues = pd.DataFrame(data, columns=[\"number\", \"title\",\n",
    "                                     \"labels\", \"state\"])\n",
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interacting-with-databases'></a>\n",
    "# Interacting with Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sqlite database \n",
    "import sqlite3\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    " c REAL,        d INTEGER\n",
    ");\"\"\"\n",
    "\n",
    "con = sqlite3.connect(\"mydata.sqlite\")\n",
    "con.execute(query)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the database using SQL statement\n",
    "data = [(\"Atlanta\", \"Georgia\", 1.25, 6),\n",
    "        (\"Tallahassee\", \"Florida\", 2.6, 3),\n",
    "        (\"Sacramento\", \"California\", 1.7, 5)]\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data from database using sql query\n",
    "cursor = con.execute(\"SELECT * FROM test\")\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to pull from the cursor\n",
    "cursor.description\n",
    "pd.DataFrame(rows, columns=[x[0] for x in cursor.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sqlalchemy as an alternative to read with engine, rather than cursor\n",
    "import sqlalchemy as sqla\n",
    "db = sqla.create_engine(\"sqlite:///mydata.sqlite\")\n",
    "pd.read_sql(\"SELECT * FROM test\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete database\n",
    "!rm mydata.sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='in-class-problems'></a>\n",
    "# In Class Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    #1\n",
    "    Create a dataframe of the file called 'tips' from the examples folder\n",
    "    How many rows and columns?\n",
    "    Look at the first 5 rows and last 5 rows?\n",
    "    Print the column names\n",
    "    Print the column datatypes\n",
    "    What is the independent variables?\n",
    "'''\n",
    "'''\n",
    "    #2\n",
    "    Calculate summary statistics\n",
    "    What percent of observations were smokers?\n",
    "    What is the distribution of days of week?\n",
    "    What is the distribution of time?\n",
    "    What is the average size?\n",
    "    What is the averae percentage tip?\n",
    "'''\n",
    "'''\n",
    "    #3\n",
    "    Write the table to a json that is a list of dictionaries where the list is 244 long\n",
    "    Create a sqlite database and load the dataframe to the database\n",
    "'''\n",
    "'''\n",
    "    #4\n",
    "    Build a correlation matrix\n",
    "    Create a model that predicts tip amount\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
